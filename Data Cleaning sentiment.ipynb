{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from itertools import repeat\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mosestokenizer import MosesTokenizer, MosesDetokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/AYAN/Downloads/archive (1)/raw_partner_headlines.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.iloc[:200000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "m = data.shape[0]\n",
    "for i in range(m):\n",
    "    text = data[\"headline\"][i]\n",
    "    tokens = word_tokenize(str(text))\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    table = (str).maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    porter = WordNetLemmatizer()\n",
    "    stemmed = [porter.lemmatize(word , 'n') for word in words]\n",
    "    stemmed2 = [porter.lemmatize(word , 'v') for word in stemmed]\n",
    "    #print(stemmed2)\n",
    "    #detokenizer = TreebankWordDetokenizer().detokenize(lst)\n",
    "    data['headline'][i] = TreebankWordDetokenizer().detokenize(stemmed2)\n",
    "    #print(i)\n",
    "    #detokenizer(stemmed2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>stock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>agilent technology announce price million seni...</td>\n",
       "      <td>http://www.gurufocus.com/news/1153187/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-06-01 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>agilent gear earn card</td>\n",
       "      <td>http://www.zacks.com/stock/news/931205/agilent...</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>2020-05-18 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>jp morgan asset management announce liquidatio...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138923/jp-morga...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>pershing square capital management lp buy agil...</td>\n",
       "      <td>http://www.gurufocus.com/news/1138704/pershing...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-15 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>agilent award trilogy science golden ticket la...</td>\n",
       "      <td>http://www.gurufocus.com/news/1134012/agilent-...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2020-05-12 00:00:00</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>200512</td>\n",
       "      <td>paul singer elliott management set date barnes...</td>\n",
       "      <td>http://www.gurufocus.com/news/891189/paul-sing...</td>\n",
       "      <td>GuruFocus</td>\n",
       "      <td>2019-06-07 00:00:00</td>\n",
       "      <td>BKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>200513</td>\n",
       "      <td>sny czr among premarket gainer</td>\n",
       "      <td>https://seekingalpha.com/news/3469821-sny-czr-...</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>2019-06-07 00:00:00</td>\n",
       "      <td>BKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>200514</td>\n",
       "      <td>jolt gamestop barnes noble buyout</td>\n",
       "      <td>https://seekingalpha.com/news/3469811-jolt-gam...</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>2019-06-07 00:00:00</td>\n",
       "      <td>BKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>200515</td>\n",
       "      <td>another stellar job report wall street breakfa...</td>\n",
       "      <td>https://seekingalpha.com/article/4268970-anoth...</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>2019-06-07 00:00:00</td>\n",
       "      <td>BKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>200516</td>\n",
       "      <td>barnes noble take buyout deal elliott</td>\n",
       "      <td>https://seekingalpha.com/news/3469769-barnes-a...</td>\n",
       "      <td>Seeking Alpha</td>\n",
       "      <td>2019-06-07 00:00:00</td>\n",
       "      <td>BKS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                           headline  \\\n",
       "0                2  agilent technology announce price million seni...   \n",
       "1                3                             agilent gear earn card   \n",
       "2                4  jp morgan asset management announce liquidatio...   \n",
       "3                5  pershing square capital management lp buy agil...   \n",
       "4                6  agilent award trilogy science golden ticket la...   \n",
       "...            ...                                                ...   \n",
       "199995      200512  paul singer elliott management set date barnes...   \n",
       "199996      200513                     sny czr among premarket gainer   \n",
       "199997      200514                  jolt gamestop barnes noble buyout   \n",
       "199998      200515  another stellar job report wall street breakfa...   \n",
       "199999      200516              barnes noble take buyout deal elliott   \n",
       "\n",
       "                                                      url      publisher  \\\n",
       "0       http://www.gurufocus.com/news/1153187/agilent-...      GuruFocus   \n",
       "1       http://www.zacks.com/stock/news/931205/agilent...          Zacks   \n",
       "2       http://www.gurufocus.com/news/1138923/jp-morga...      GuruFocus   \n",
       "3       http://www.gurufocus.com/news/1138704/pershing...      GuruFocus   \n",
       "4       http://www.gurufocus.com/news/1134012/agilent-...      GuruFocus   \n",
       "...                                                   ...            ...   \n",
       "199995  http://www.gurufocus.com/news/891189/paul-sing...      GuruFocus   \n",
       "199996  https://seekingalpha.com/news/3469821-sny-czr-...  Seeking Alpha   \n",
       "199997  https://seekingalpha.com/news/3469811-jolt-gam...  Seeking Alpha   \n",
       "199998  https://seekingalpha.com/article/4268970-anoth...  Seeking Alpha   \n",
       "199999  https://seekingalpha.com/news/3469769-barnes-a...  Seeking Alpha   \n",
       "\n",
       "                       date stock  \n",
       "0       2020-06-01 00:00:00     A  \n",
       "1       2020-05-18 00:00:00     A  \n",
       "2       2020-05-15 00:00:00     A  \n",
       "3       2020-05-15 00:00:00     A  \n",
       "4       2020-05-12 00:00:00     A  \n",
       "...                     ...   ...  \n",
       "199995  2019-06-07 00:00:00   BKS  \n",
       "199996  2019-06-07 00:00:00   BKS  \n",
       "199997  2019-06-07 00:00:00   BKS  \n",
       "199998  2019-06-07 00:00:00   BKS  \n",
       "199999  2019-06-07 00:00:00   BKS  \n",
       "\n",
       "[200000 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('C:/Users/AYAN/Downloads/archive (1)/cleaned_master_news.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"argue\" , \"argued\"]\n",
    "a = [lemmatizer.lemmatize(words) for words in a]\n",
    "a = [porter.stem(words) for words in a]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv(\"/home/ayan.kundu/stock prediction/cleaned_demo_dataset2.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       False\n",
       "1       False\n",
       "2       False\n",
       "3       False\n",
       "4       False\n",
       "5       False\n",
       "6       False\n",
       "7       False\n",
       "8       False\n",
       "9       False\n",
       "10      False\n",
       "11      False\n",
       "12      False\n",
       "13      False\n",
       "14      False\n",
       "15      False\n",
       "16      False\n",
       "17      False\n",
       "18      False\n",
       "19      False\n",
       "20      False\n",
       "21      False\n",
       "22      False\n",
       "23      False\n",
       "24      False\n",
       "25      False\n",
       "26      False\n",
       "27      False\n",
       "28      False\n",
       "29      False\n",
       "        ...  \n",
       "2769    False\n",
       "2770    False\n",
       "2771    False\n",
       "2772    False\n",
       "2773    False\n",
       "2774    False\n",
       "2775    False\n",
       "2776    False\n",
       "2777    False\n",
       "2778    False\n",
       "2779    False\n",
       "2780    False\n",
       "2781    False\n",
       "2782    False\n",
       "2783    False\n",
       "2784    False\n",
       "2785    False\n",
       "2786    False\n",
       "2787    False\n",
       "2788    False\n",
       "2789    False\n",
       "2790    False\n",
       "2791    False\n",
       "2792    False\n",
       "2793    False\n",
       "2794    False\n",
       "2795    False\n",
       "2796    False\n",
       "2797    False\n",
       "2798    False\n",
       "Name: News_Text, Length: 2799, dtype: bool"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"News_Text\"]==\"Nan\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
