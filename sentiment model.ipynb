{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Input , Dropout , LSTM , Activation , TimeDistributed , Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.regularizers import l1,l2\n",
    "from nltk.tokenize import word_tokenize\n",
    "from itertools import repeat\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_excel(\"C:/Users/AYAN/Downloads/archive (1)/df_score.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train[['headline','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train[\"headline\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    195454\n",
       "-1      2734\n",
       " 1      1812\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[\"score\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(x_train)):\n",
    "    x_train[i] = str(x_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train=X_train[\"score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y_train[Y_train == -1] = \"N\"\n",
    "Y_train[Y_train == 0] = \"NE\"\n",
    "Y_train[Y_train == 1] = \"P\"\n",
    "\n",
    "\n",
    "\n",
    "Y_train[Y_train == \"N\"] = 0\n",
    "Y_train[Y_train == \"NE\"] = 1\n",
    "Y_train[Y_train == \"P\"] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    195454\n",
       "0      2734\n",
       "2      1812\n",
       "Name: score, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file,encoding=\"utf8\") as f:\n",
    "        words = set()\n",
    "        word_to_vec_map = {}\n",
    "        for line in f:\n",
    "            line = line.strip().split()\n",
    "        \n",
    "            curr_word = line[0]\n",
    "            words.add(curr_word)\n",
    "            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n",
    "\n",
    "        i = 1\n",
    "        words_to_index = {}\n",
    "        index_to_words = {}\n",
    "        for w in sorted(words):\n",
    "            words_to_index[w] = i\n",
    "            index_to_words[i] = w\n",
    "            i = i + 1\n",
    "    return words_to_index, index_to_words, word_to_vec_map\n",
    "words_to_index , index_to_words , words_to_vec_map = read_glove_vecs(\"C:/Users/AYAN/Downloads/glove.6B.100d.txt/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, words_to_index, max_len):\n",
    "    m = X.shape[0]                                   # number of training examples\n",
    "    X_indices = np.zeros((m, max_len))\n",
    "    for i in range(m):                               # loop over training examples\n",
    "        words = word_tokenize(X[i])\n",
    "        if len(words) <= max_len:\n",
    "            words.extend(repeat(0 , max_len - len(words)))\n",
    "        else :\n",
    "            words = words[0:max_len]\n",
    "        for j in range(max_len):\n",
    "            try:\n",
    "                X_indices[i, j] = words_to_index[words[j]]\n",
    "            except :\n",
    "                X_indices[i, j] = words_to_index['unk']\n",
    "    return X_indices\n",
    "\n",
    "\n",
    "def Emojify_V2(input_shape, words_to_vec_map, words_to_index , emb_matrix):\n",
    "    \n",
    "    maxlen = input_shape[0]\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(400001 , 100 , input_length = maxlen , weights = [emb_matrix] , trainable = False))\n",
    "    model.add(Conv1D(filters = 100, kernel_size = 2, strides = 2 , padding='same' , activation = 'relu',kernel_regularizer = l2(0.01)))\n",
    "    model.add(MaxPooling1D(pool_size = 2 , strides = 2))\n",
    "\n",
    "    model.add(Bidirectional(LSTM(256,return_sequences = True ,kernel_regularizer=l2(0.008))))    \n",
    "    model.add(Bidirectional(LSTM(256,return_sequences = False ,kernel_regularizer=l2(0.008))))\n",
    "    model.add (Dense(3,kernel_regularizer = l2(0.0085)))\n",
    "    \n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AYAN\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass classes=[0 1 2], y=0         1\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         1\n",
      "         ..\n",
      "199995    1\n",
      "199996    1\n",
      "199997    1\n",
      "199998    1\n",
      "199999    1\n",
      "Name: score, Length: 200000, dtype: object as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n"
     ]
    }
   ],
   "source": [
    "class_weight1 = dict(zip(np.unique(Y_train), class_weight.compute_class_weight('balanced', np.unique(Y_train), \n",
    "                Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 24.384296513045598, 1: 0.3410862231863593, 2: 36.79175864606328}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weight1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_matrix = np.zeros((400001, 100))\n",
    "for word, index in words_to_index.items():\n",
    "        emb_matrix[index, :] = words_to_vec_map[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001, 100)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain , xtest , ytrain , ytest = train_test_split(x_train , Y_train , test_size = 0.2 , stratify = Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(ytrain)\n",
    "encoded_Y = encoder.transform(ytrain)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "Y = to_categorical(encoded_Y)\n",
    "\n",
    "encoder1 = LabelEncoder()\n",
    "encoder1.fit(ytest)\n",
    "encoded_Y1 = encoder1.transform(ytest)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "Y_test = to_categorical(encoded_Y1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Y = to_categorical(ytrain)\n",
    "#Y_test = to_categorical(ytest.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_9 (Embedding)      (None, 256, 100)          40000100  \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 128, 100)          20100     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 64, 100)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_16 (Bidirectio (None, 64, 512)           731136    \n",
      "_________________________________________________________________\n",
      "bidirectional_17 (Bidirectio (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 3)                 1539      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 3)                 12        \n",
      "=================================================================\n",
      "Total params: 42,327,799\n",
      "Trainable params: 2,327,699\n",
      "Non-trainable params: 40,000,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify_V2((256,), words_to_vec_map, words_to_index , emb_matrix)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.05)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_indices(xtrain, words_to_index, 256)\n",
    "X_test_indices = sentences_to_indices(xtest, words_to_index, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(160000, 256)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[343465., 294037., 167678., ..., 372306., 372306., 372306.],\n",
       "       [ 76672., 153292., 243876., ..., 372306., 372306., 372306.],\n",
       "       [293041., 348600., 273028., ..., 372306., 372306., 372306.],\n",
       "       ...,\n",
       "       [ 49059., 188692.,  49256., ..., 372306., 372306., 372306.],\n",
       "       [393658., 359889., 234840., ..., 372306., 372306., 372306.],\n",
       "       [256861., 110156., 354594., ..., 372306., 372306., 372306.]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 165/2500 [>.............................] - ETA: 1:25:17 - loss: 7.2064 - categorical_accuracy: 0.3862"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_indices, Y, epochs = 10, batch_size = 64, class_weight=class_weight1,validation_data = (X_test_indices , Y_test) , shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices2(X, words_to_index, max_len):\n",
    "    \n",
    "    X_indices = np.zeros((max_len))                          \n",
    "    sentence_words = [w.lower() for w in str(X).split()]    \n",
    "    j = 0    \n",
    "    for w in range(max_len):\n",
    "            try:\n",
    "                X_indices[j] = words_to_index[sentence_words[w]]\n",
    "                j += 1\n",
    "            except :\n",
    "                \n",
    "                X_indices[j] = words_to_index['unk']\n",
    "                j += 1\n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"Zara India reported 72% increase in its profit to Rs 82.59 crore in FY18, driven by strong sales and lower price points that helped the company acquire new customers.Zara brand-owner Inditex and the Tata Group’s retail arm Trent, which runs Zara stores in India, reported 19.4% increase in net sales to Rs 1,221.67 crore, according to Trent’s annual report released on Friday.The Company has two separate joint ventures with the Inditex group of Spain with a shareholding of 51% (Inditex) and 49% (Trent) — one for Zara and the other for Massimo Dutti stores in India. The joint venture for Zara operates 20 stores in Delhi, Mumbai, Bengaluru, Pune, Surat, Jaipur, Chandigarh, Chennai, Mohali, Hyderabad and Gurgaon.Plans are to steadily expand the presence of Zara stores in India over the next three to four years in the major cities . The primary challenge to faster expansion is the availability of high quality retail spaces which can be expected to generate reasonable sales turnover, the company said in the report.Including in the context of brand ownership and the arrangements for merchandise supply with the majority partner entirely controlling the core customer proposition with respect to the fashion, the company views its commitment to this joint venture primarily as a financial investment and consequently, it may be appropriate not to consider this as a long-term strategic investment integral to other retail operations. The joint venture for Massimo Dutti operates three stores in Mumbai and Delhi, and this joint venture entity Massimo Dutti recorded total revenues of Rs 45.75 crore.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "test_indices = sentences_to_indices2(text, words_to_index, 256)\n",
    "test_indices = test_indices.reshape(1,256)\n",
    "pred = model.predict_classes(test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model_sentiment.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"model_sentiment.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
